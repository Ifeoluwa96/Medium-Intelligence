{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "data.reverse()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c2842511c116>, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c2842511c116>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    out = [self.neuron_value[neuron_string][enum]+=self.cost_function(l,\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Network_classify:\n",
    "    def __init__(self, layers, data, target):\n",
    "        #layers have to be numbers of neurons for each layer\n",
    "        self.no_of_layers = len(layers)\n",
    "        self.layers = layers\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.eval_fit = []\n",
    "        var = 0\n",
    "        \n",
    "        \n",
    "        #pre-initialize weights\n",
    "        self.weights = {}\n",
    "        for k in layers:\n",
    "            self.weights['weight'+str(k)] = np.random.randn(int(k))\n",
    "            \n",
    "            \n",
    "        #pre-intialize biases\n",
    "        for k in layers:\n",
    "            self.biases['bias'+str(k)] = np.random.randn(int(k))\n",
    "            \n",
    "        #pre_initialized Neuron_value\n",
    "        for k in layers:\n",
    "            self.neuron_value['neuron'+str(k)] = np.random.randn(int(k))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def cost_function(self, x, weight, bias):\n",
    "        return x*weight + bias\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x_val):\n",
    "        # at the layer\n",
    "        for k in self.layer:\n",
    "            neuron_string = 'neuron'+str(k)\n",
    "            weight_string = 'weight'+ str(k)\n",
    "            bias_string = 'bias'+str(k)\n",
    "            \n",
    "            \n",
    "            #update each neuron value from curent weight and bias\n",
    "            for enum,i in enumerate(self.neuron_value[neuron_string]):\n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                serious correction is needed here in updating neuron values\n",
    "                \"\"\"\n",
    "                out = [self.neuron_value[neuron_string][enum]+=self.cost_function(l,\n",
    "                                               self.weights[weight_string][enum],\n",
    "                                               self.bias[bias_string][enum]) for l in x_val]\n",
    "            x_val = self.neuron_value[neuron_string]\n",
    "        return \n",
    "    \n",
    "    \n",
    "    def feedforward(self,x):\n",
    "        for val_x in x:\n",
    "            out = [self.forward(val_x) for k in val_x]\n",
    "        return\n",
    "    \n",
    "    def update(self, weight_string,bias_string,neuron_string enum,learning_rate):\n",
    "        current_neuron_value = self.neuron_value[neuron_string][enum]\n",
    "        self.weights[weight_string][enum] -= learning_rate* current_neuron_value\n",
    "        self.bias[bias_string][enum] -= learning_rate\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def backprop(self, learning_rate):\n",
    "        copy_layer = self.layers\n",
    "        copy_layer.reverse()\n",
    "        for k in copy_layer:\n",
    "            neuron_string = 'neuron'+str(k)\n",
    "            weight_string = 'weight'+ str(k)\n",
    "            bias_string = 'bias'+str(k)\n",
    "            \n",
    "            out = [self.update(weight_string, bias_string,\n",
    "                               neuron_string, enum, \n",
    "                               learning_rate) for enum,i in enumerate(self.neuron_value[neuron_string])]\n",
    "            \n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, data, target,epochs, learning_rate, batch_size = 50, metric =['Accuracy', 'precision','f1_score']):\n",
    "        \"\"\"\n",
    "            Fit in batches and compute for each epoch epochs per batch\n",
    "        \n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            # feed forward\n",
    "            self.feedforward(data)\n",
    "            \n",
    "            # backpropagation \n",
    "            self.backprop(learning_rate)\n",
    "            \n",
    "            # evaluation\n",
    "            score = self.evaluate(data,y, evaluation_type = metric)\n",
    "            self.eval_fit[str(i)] = score\n",
    "        return\n",
    "    \n",
    "    def evaluate(self, data, y, evaluation_type = ['accuracy','f1_score','precision']):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def plot_training(self):\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        #self.eval_fit\n",
    "        x = self.eval_fit.keys()\n",
    "        y = self.eval_fit.values\n",
    "        \n",
    "        sns.lineplot(x,y)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def save_model(self, model = 'All'):\n",
    "        \"\"\"\n",
    "        model can be: bias, weights, neuron_values\n",
    "        save biases\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        # write a file\n",
    "        f = open(\"model.pkl\", \"w\")\n",
    "        #dump biases\n",
    "        pickle.dump(self.biases, f)\n",
    "        #dump weights\n",
    "        pickle.dump(self.weights,f)\n",
    "        #dump neuron values\n",
    "        pickle.dump(self.neuron_value, f)\n",
    "        f.close()\n",
    "        return\n",
    "    \n",
    "    def load_model(self,model_dir =''):\n",
    "        f = open(model_dir, \"r\")\n",
    "        biases = pickle.load(f)\n",
    "        weights = pickle.load(f)\n",
    "        neurons = pickle.load(f)\n",
    "        f.close()\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, values):\n",
    "        #\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_regression:\n",
    "    def __init__(self, layers, data, target):\n",
    "        #layers have to be numbers of neurons for each layer\n",
    "        self.no_of_layers = len(layers)\n",
    "        self.layers = layers\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.eval_fit = []\n",
    "        var = 0\n",
    "        \n",
    "        \n",
    "        #pre-initialize weights\n",
    "        self.weights = {}\n",
    "        for k in layers:\n",
    "            self.weights['weight'+str(k)] = np.random.randn(int(k))\n",
    "            \n",
    "            \n",
    "        #pre-intialize biases\n",
    "        for k in layers:\n",
    "            self.biases['bias'+str(k)] = np.random.randn(int(k))\n",
    "            \n",
    "        #pre_initialized Neuron_value\n",
    "        for k in layers:\n",
    "            self.neuron_value['neuron'+str(k)] = np.random.randn(int(k))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def cost_function(self, x, weight, bias):\n",
    "        return x*weight + bias\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x_val):\n",
    "        # at the layer\n",
    "        for k in self.layer:\n",
    "            neuron_string = 'neuron'+str(k)\n",
    "            weight_string = 'weight'+ str(k)\n",
    "            bias_string = 'bias'+str(k)\n",
    "            \n",
    "            \n",
    "            #update each neuron value from curent weight and bias\n",
    "            for enum,i in enumerate(self.neuron_value[neuron_string]):\n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                serious correction is needed here in updating neuron values\n",
    "                \"\"\"\n",
    "                out = [self.neuron_value[neuron_string][enum]+=self.cost_function(l,\n",
    "                                               self.weights[weight_string][enum],\n",
    "                                               self.bias[bias_string][enum]) for l in x_val]\n",
    "            x_val = self.neuron_value[neuron_string]\n",
    "        return \n",
    "    \n",
    "    \n",
    "    def feedforward(self,x):\n",
    "        for val_x in x:\n",
    "            out = [self.forward(val_x) for k in val_x]\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def backprop(self, x, y, learning_rate):\n",
    "        \"\"\"\n",
    "        Unfinished:\n",
    "        need to iterate from the front to the back\n",
    "        updating each weights and biases without tampering with the neuron values.\n",
    "        \"\"\"\n",
    "        copy_layer = self.layers\n",
    "        copy_layer.reverse()\n",
    "        for k in copy_layer:\n",
    "            \n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, data, target,epochs, learning_rate, batch_size = 50, metric =['Accuracy', 'precision','f1_score']):\n",
    "        for i in range(epochs):\n",
    "            # feed forward\n",
    "            self.feedforward(data)\n",
    "            \n",
    "            # backpropagation \n",
    "            self.backprop(data, target, learning_rate = learning_rate)\n",
    "            \n",
    "            # evaluation\n",
    "            score = self.evaluate(data,y, evaluation_type = metric)\n",
    "            self.eval_fit[str(i)] = score\n",
    "        return\n",
    "    \n",
    "    def evaluate(self, data, y, evaluation_type = ['accuracy','f1_score','precision']):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def plot_training(self):\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        #self.eval_fit\n",
    "        x = self.eval_fit.keys()\n",
    "        y = self.eval_fit.values\n",
    "        \n",
    "        sns.lineplot(x,y)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def save_model(self, model = 'All'):\n",
    "        \"\"\"\n",
    "        model can be: bias, weights, neuron_values\n",
    "        save biases\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        # write a file\n",
    "        f = open(\"model.pkl\", \"w\")\n",
    "        #dump biases\n",
    "        pickle.dump(self.biases, f)\n",
    "        #dump weights\n",
    "        pickle.dump(self.weights,f)\n",
    "        #dump neuron values\n",
    "        pickle.dump(self.neuron_value, f)\n",
    "        f.close()\n",
    "        return\n",
    "    \n",
    "    def load_model(self,model_dir =''):\n",
    "        f = open(model_dir, \"r\")\n",
    "        biases = pickle.load(f)\n",
    "        weights = pickle.load(f)\n",
    "        neurons = pickle.load(f)\n",
    "        f.close()\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, values):\n",
    "        #\n",
    "        return classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
